# Prerequisites
#  bin/logstash-plugin install logstash-filter-prune
#  bin/logstash-plugin install logstash-filter-http
#  bin/logstash-plugin install logstash-filter-split

input {

  # 1. Kick off with the login poll
  http_poller {
    urls => {
      login => {
        # Supports all options supported by ruby's Manticore HTTP client
        method => post
        url => "https://anypoint.mulesoft.com/accounts/login"
        headers => {
          "Content-Type" => "application/x-www-form-urlencoded"
        }
        body => "username=${CH_USER}&password=${CH_PASSWORD}"
     }
    }
    request_timeout => 120
    # Supports "cron", "every", "at" and "in" schedules by rufus scheduler
    schedule => { cron => "* * * * * UTC"}
    codec => "json"
    # A hash of request metadata info (timing, response headers, etc.) will be sent here
    # metadata_target => "http_poller_metadata"
  }
}

filter {
  ruby {
    code => "event.set('now_ms', Time.now.to_i * 1000)"
  }

  # After login, leave just the access_token
  prune {
    whitelist_names => [ "now_ms", "access_token" ]
  }


  # 2. Get organization.id
  http {
    url => "https://anypoint.mulesoft.com/accounts/api/me"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
    }
  }
  mutate {
    add_field => {
      organization_id => "%{[body][user][organization][id]}"
    }
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id"]
  }


  # 3. Get environment_id
  http {
    url => "https://anypoint.mulesoft.com/accounts/api/organizations/%{organization_id}/environments"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
    }
  }
  #   {
  #     "data": [
  #         {
  #             "id": "ef631804-77e7-4dc0-a1e2-a18aaa256ea7",
  #             "name": "Design",
  #             "organizationId": "28ed3785-e975-414e-ac98-275c74e5a249",
  #             "isProduction": false,
  #             "type": "design",
  #             "clientId": "5f4919135f27450ab92cae2661d3d2df"
  #         },
  #         {
  #             "id": "9ecd6373-7d0c-45a0-974b-c5caa72ea9ab",
  #             "name": "Production",
  #             "organizationId": "28ed3785-e975-414e-ac98-275c74e5a249",
  #             "isProduction": true,
  #             "type": "production",
  #             "clientId": "87df2875707c4cf1b6f6cda246a5ff18"
  #         }
  #     ],
  #     "total": 3
  # }
  ruby {
    code => "
    value = event.get('body')['data'].find {|h| h['name'] == '${CH_ENV:Production}'}['id']
    event.set('environment_id', value)
    "
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id", "environment_id"]
    add_field => {
      "environment_name" => "${CH_ENV:Production}"
    }
  }

  # 4. Get applications
  http {
    url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
      "X-ANYPNT-ENV-ID" => "%{environment_id}"
      "Content-Type" => "application/json"
    }
  }
  # Split and create separate events for every application record
  split {
    field => "body"
  }
  mutate {
    add_field => {
      app_name => "%{[body][domain]}"
    }
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id", "environment_id", "environment_name", "deployment_id", "app_name"]
  }


  # 5. Get deployment_id
  http {
    url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/deployments"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
      "X-ANYPNT-ENV-ID" => "%{environment_id}"
      "Content-Type" => "application/json"
    }
  }
  # Split and create separate events for all deployments, including empty ones
  split {
    field => "body[data]"
  }
  mutate {
    add_field => {
      deployment_id => "%{[body][data][deploymentId]}"
    }
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id", "environment_id", "environment_name", "app_name", "deployment_id"]
  }

  # 6. Get latest_record_id
  elasticsearch {
    hosts => ["${ES_HOST:http\://localhost:9200}"]
    # filebeat-* works with Infra Logs view. Can be changed in Kibana:
    # xpack.infra.sources.default.logAlias
    index => "filebeat-*"
    user => "${ES_USER:elastic}"
    password => "${ES_PASS:changeme}"
    query => "app_name:%{app_name} AND deployment_id:%{deployment_id}"
    result_size => 1
    sort => "@timestamp:desc,line:desc"
    fields => {
      "record_id" => "latest_record_id"
    }
  }


  # 7. Get logs

  # If it is not a first request, use latest_record_id
  if "" in [latest_record_id] {
    http {
      connect_timeout => 120
      request_timeout => 120
      socket_timeout => 120
      url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/logs"
      verb => POST
      headers => {
        Authorization => "Bearer %{access_token}"
        "Content-Type" => "application/json"
        "X-ANYPNT-ENV-ID" => "%{environment_id}"
        "X-ANYPNT-ORG-ID" => "%{organization_id}"
      }
      body => {
        deploymentId => "%{deployment_id}"
        startTime => 0
        endTime => "%{now_ms}"
        limitMsgLen => 5000
        limit => "${NUM_LOG_LINES:250}"
        lowerId => "%{latest_record_id}"
      }
      body_format => json
    }
  } else {
    # First batch request without latest_record_id
    mutate {
      remove_tag => [ "_elasticsearch_lookup_failure" ]
    }

    http {
      connect_timeout => 120
      request_timeout => 120
      socket_timeout => 120
      url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/logs"
      verb => POST
      headers => {
        Authorization => "Bearer %{access_token}"
        "Content-Type" => "application/json"
        "X-ANYPNT-ENV-ID" => "%{environment_id}"
        "X-ANYPNT-ORG-ID" => "%{organization_id}"
      }
      body => {
        deploymentId => "%{deployment_id}"
        startTime => 0
        endTime => "%{now_ms}"
        limitMsgLen => 5000
        limit => "${NUM_LOG_LINES:250}"
      }
      body_format => json
    }
  }

  # Drop all empty bodies and error responses
  if "_httprequestfailure" in [tags] or [body.length] == 0 {
    drop {}
  }

  # Split the records and remap
  split {
    field => "body"
  }

  mutate {
    add_field => {
      "instance_id" => "%{[body][instanceId]}"
      "line" => "%{[body][line]}"
      "record_id" => "%{[body][recordId]}"
      "priority" => "%{[body][event][priority]}"
      "logger_name" => "%{[body][event][loggerName]}"
      "thread_name" => "%{[body][event][threadName]}"
      "timestamp1" => "%{[body][event][timestamp]}"
      "message" => "%{[body][event][message]}"
    }
  }
  mutate {
    convert => {
      "line" => "integer"
      "timestamp1" => integer
    }
  }

  date {
    match => [ "timestamp1", "UNIX_MS" ]
  }

  prune {
    blacklist_names => ["now_ms", "body", "timestamp1", "access_token", "headers", "now_ms", "latest_record_id"]
  }

}

output {
  #stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["${ES_HOST:http\://localhost:9200}"]
    # filebeat-* works with Infra Logs view. Can be changed in Kibana:
    # xpack.infra.sources.default.logAlias
    index => "filebeat-%{+YYYY.MM.dd}"
    user => "${ES_USER:elastic}"
    password => "${ES_PASS:changeme}"
    document_id => "%{record_id}"
    manage_template => true
    template => "templates/filebeat_template.json"
    template_name => "filebeat-*"
    template_overwrite => true
  }
}
