input {
  pipeline {
    address => "logs"
  }
}

filter {
  # 1. Get applications
  http {
    url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
      "X-ANYPNT-ENV-ID" => "%{environment_id}"
      "Content-Type" => "application/json"
    }
  }
  # Split and create separate events for every application record
  split {
    field => "body"
  }
  mutate {
    add_field => {
      app_name => "%{[body][domain]}"
    }
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id", "environment_id", "environment_name", "deployment_id", "app_name"]
  }


  # 2. Get deployment_id
  http {
    url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/deployments"
    verb => GET
    headers => {
      Authorization => "Bearer %{access_token}"
      "X-ANYPNT-ENV-ID" => "%{environment_id}"
      "Content-Type" => "application/json"
    }
  }
  # Split and create separate events for all deployments, including empty ones
  split {
    field => "body[data]"
  }
  mutate {
    add_field => {
      deployment_id => "%{[body][data][deploymentId]}"
    }
  }
  prune {
    whitelist_names => [ "now_ms", "access_token", "organization_id", "environment_id", "environment_name", "app_name", "deployment_id"]
  }

  # 3. Get latest_record_id
  elasticsearch {
    hosts => ["${ES_HOST:http\://localhost:9200}"]
    # filebeat-* works with Infra Logs view. Can be changed in Kibana:
    # xpack.infra.sources.default.logAlias
    index => "filebeat-*"
    user => "${ES_USER:elastic}"
    password => "${ES_PASS:changeme}"
    query => "app_name:%{app_name} AND deployment_id:%{deployment_id}"
    result_size => 1
    sort => "@timestamp:desc,line:desc"
    fields => {
      "record_id" => "latest_record_id"
    }
  }


  # 4. Get logs

  # If it is not a first request, use latest_record_id
  if "" in [latest_record_id] {
    http {
      connect_timeout => 120
      request_timeout => 120
      socket_timeout => 120
      url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/logs"
      verb => POST
      headers => {
        Authorization => "Bearer %{access_token}"
        "Content-Type" => "application/json"
        "X-ANYPNT-ENV-ID" => "%{environment_id}"
        "X-ANYPNT-ORG-ID" => "%{organization_id}"
      }
      body => {
        deploymentId => "%{deployment_id}"
        # Change this setting to avoid log syncing since the beginning of time = 0
        startTime => 0
        endTime => "%{now_ms}"
        limitMsgLen => 5000
        limit => "${NUM_LOG_LINES:250}"
        lowerId => "%{latest_record_id}"
      }
      body_format => json
    }
  } else {
    # First batch request without latest_record_id
    mutate {
      remove_tag => [ "_elasticsearch_lookup_failure" ]
    }

    http {
      connect_timeout => 120
      request_timeout => 120
      socket_timeout => 120
      url => "https://anypoint.mulesoft.com/cloudhub/api/v2/applications/%{app_name}/logs"
      verb => POST
      headers => {
        Authorization => "Bearer %{access_token}"
        "Content-Type" => "application/json"
        "X-ANYPNT-ENV-ID" => "%{environment_id}"
        "X-ANYPNT-ORG-ID" => "%{organization_id}"
      }
      body => {
        deploymentId => "%{deployment_id}"
        startTime => 0
        endTime => "%{now_ms}"
        limitMsgLen => 5000
        limit => "${NUM_LOG_LINES:250}"
      }
      body_format => json
    }
  }

  # Drop all empty bodies and error responses
  if "_httprequestfailure" in [tags] or [body.length] == 0 {
    drop {}
  }

  # Split the records and remap
  split {
    field => "body"
  }

  mutate {
    add_field => {
      "instance_id" => "%{[body][instanceId]}"
      "line" => "%{[body][line]}"
      "record_id" => "%{[body][recordId]}"
      "priority" => "%{[body][event][priority]}"
      "logger_name" => "%{[body][event][loggerName]}"
      "thread_name" => "%{[body][event][threadName]}"
      "timestamp1" => "%{[body][event][timestamp]}"
      "message" => "%{[body][event][message]}"
    }
  }
  mutate {
    convert => {
      "line" => "integer"
      "timestamp1" => integer
    }
  }

  date {
    match => [ "timestamp1", "UNIX_MS" ]
  }

  prune {
    blacklist_names => ["now_ms", "body", "timestamp1", "access_token", "headers", "now_ms", "latest_record_id"]
  }

}

output {
  #stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["${ES_HOST:http\://localhost:9200}"]
    # filebeat-* works with Infra Logs view. Can be changed in Kibana:
    # xpack.infra.sources.default.logAlias
    index => "filebeat-%{+YYYY.MM.dd}"
    user => "${ES_USER:elastic}"
    password => "${ES_PASS:changeme}"
    document_id => "%{record_id}"
    manage_template => true
    template => "templates/filebeat_template.json"
    template_name => "filebeat-*"
    template_overwrite => true
  }
}
